{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/Jonas-Metz-verovis/verovis_Coding_Challenge/blob/main/01_Data_Loading_and_Preprocessing.ipynb)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Introduction\n",
    "\n",
    "#### In this Challenge you need to load Restaurant Rating Data and create a tree-based Classification Model to predict the Rating of a Restaurant. The Challenge will be scored based on:\n",
    "\n",
    "1.  The Predictions Model's Test Accuracy Score\n",
    "1.  The verbal Explanations for specific Processing/Modeling Choices\n",
    "1.  The Readability and Transferability of the submitted Code\n",
    "1.  The Documentation of the submitted Code\n",
    "1.  Optional (not scored): Explanation of the Model's learned Relationships (e.g. through the Feature Importances)\n",
    "\n",
    "General Machine Learning Project Checklist (**Focus of this Challenge**) by [Aurélien Géron](https://github.com/ageron/handson-ml)\n",
    "\n",
    "1. **Frame the Problem and look at the Big Picture**\n",
    "1. **Get the Data**\n",
    "1. **Explore the Data to gain Insights**\n",
    "1. **Prepare the Data to better expose the underlying Data Patterns to the used Machine Learning Algorithms**\n",
    "1. Explore many different Models and short-list the best ones\n",
    "1. Fine-tune your Models and combine them into a great Solution\n",
    "1. Present your Solution\n",
    "1. Launch, monitor, and maintain your Model/Service\n",
    "\n",
    "INFO: Instead of working with [Google Colab](https://colab.research.google.com/), which is recommended because you can get started right away, you can also work with your own Development Environment (e.g. [Visual Studio Code](https://code.visualstudio.com/)), by using [Git](https://git-scm.com/) to clone the [verovis Coding Challenge GitHub Repository](https://github.com/Jonas-Metz-verovis/verovis_Coding_Challenge)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Documentation and Support\n",
    "\n",
    "#### The following Resources might be useful to complete this Challenge:\n",
    "\n",
    "1.  [Pandas Documentation](https://pandas.pydata.org/docs/reference/index.html#api)\n",
    "1.  [Numpy Documentation](https://numpy.org/doc/stable/)\n",
    "1.  [Scikit-Learn Documentation](https://scikit-learn.org/stable/modules/classes.html)\n",
    "1.  [Category Encoders Documentation](https://contrib.scikit-learn.org/category_encoders/)\n",
    "1.  [Imbalanced-Learn Documentation](https://imbalanced-learn.readthedocs.io/en/stable/api.html)\n",
    "1.  [Seaborn Documentation](https://seaborn.pydata.org/api.html)\n",
    "1.  [SHAP Documentation](https://shap.readthedocs.io/en/latest/api.html)\n",
    "1.  [Pandas Data Wrangling Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "1.  [TowardsDataScience: Data Cleansing](https://towardsdatascience.com/data-cleaning-in-python-the-ultimate-guide-2020-c63b88bf0a0d)\n",
    "1.  [TowardsDataScience: Data Preprocessing](https://towardsdatascience.com/data-preprocessing-concepts-fa946d11c825)\n",
    "1.  [TowardsDataScience: Feature Engineering](https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114)\n",
    "1.  [Machine Learning Mastery: Feature Engineering](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)\n",
    "1.  [TowardsDataScience: Working with Numerical Variables](https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b)\n",
    "1.  [TowardsDataScience: Working with Categorical Variables](https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63)\n",
    "1.  [TowardsDataScience: Categorical Variable Encoding](https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02)\n",
    "1.  [TowardsDataScience: One-Hot-Encoding for tree-based Models](https://towardsdatascience.com/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769)\n",
    "1.  [Stat Trek: One-Hot-Encoding (Dummy Variables)](https://stattrek.com/multiple-regression/dummy-variables.aspx)\n",
    "\n",
    "#### If you don't know how to find a Solution to a given Problem, it often works well if one just \"googles the problem\". Great Sources are:\n",
    "\n",
    "1.  [TowardsDataScience](https://towardsdatascience.com/)\n",
    "1.  [StackOverflow](https://stackoverflow.com/)\n",
    "1.  [Machine Learning Mastery](https://machinelearningmastery.com/start-here/)\n",
    "1.  [Python-Kurs.eu](https://www.python-kurs.eu/python3_kurs.php)\n",
    "1.  [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook)\n",
    "1.  [The Hitchhiker's Guide to Python](https://docs.python-guide.org/)\n",
    "1.  [Overview of Data Science YouTube Channels](https://towardsdatascience.com/top-20-youtube-channels-for-data-science-in-2020-2ef4fb0d3d5)\n",
    "1.  [Introduction to Machine Learning with Python](https://github.com/amueller/introduction_to_ml_with_python) / [Buy the Book](https://www.amazon.de/Introduction-Machine-Learning-Python-Scientists/dp/1449369413)\n",
    "1.  [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12_toc.pdf)\n",
    "1.  [Bayesian Reasoning and Machine Learning](http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/200620.pdf)\n",
    "1.  [Deep Learning](https://www.deeplearningbook.org/)\n",
    "\n",
    "#### The Challenge was created by [Jonas Metz](jmetz@verovis.com), please contact me anytime, if you have any Questions! :-)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Global Flags\n",
    "\n",
    "INFO: Please select a creative Team Name :-)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAM_NAME = \"HelloWorldTeam\""
   ]
  },
  {
   "source": [
    "# Imports\n",
    "\n",
    "### Info (Google Colab)\n",
    "\n",
    "If you are working in Google Colab, you can install necessary (and not already installed) Packages by running e.g.\n",
    "\n",
    "```\n",
    "!pip install shap\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from joblib import dump, load"
   ]
  },
  {
   "source": [
    "# Data Loading"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Task: Load the Data from these CSV-Files into separate Pandas DataFrames.\n",
    "\n",
    "1.  Restaurant_Accepts.csv: https://raw.githubusercontent.com/Jonas-Metz-verovis/verovis_Coding_Challenge/main/Data/Restaurant_Accepts.csv\n",
    "1.  Restaurant_Cuisine.csv: https://raw.githubusercontent.com/Jonas-Metz-verovis/verovis_Coding_Challenge/main/Data/Restaurant_Cuisine.csv\n",
    "1.  Restaurant_Location.csv: https://raw.githubusercontent.com/Jonas-Metz-verovis/verovis_Coding_Challenge/main/Data/Restaurant_Location.csv\n",
    "1.  Restaurant_Opening_Hours.csv: https://raw.githubusercontent.com/Jonas-Metz-verovis/verovis_Coding_Challenge/main/Data/Restaurant_Opening_Hours.csv\n",
    "1.  Restaurant_Parking.csv: https://raw.githubusercontent.com/Jonas-Metz-verovis/verovis_Coding_Challenge/main/Data/Restaurant_Parking.csv\n",
    "1.  Restaurant_Rating.csv: https://raw.githubusercontent.com/Jonas-Metz-verovis/verovis_Coding_Challenge/main/Data/Restaurant_Rating.csv\n",
    "1.  Restaurant_User_Cuisine.csv: https://raw.githubusercontent.com/Jonas-Metz-verovis/verovis_Coding_Challenge/main/Data/Restaurant_User_Cuisine.csv\n",
    "1.  Restaurant_User_Payment.csv: https://raw.githubusercontent.com/Jonas-Metz-verovis/verovis_Coding_Challenge/main/Data/Restaurant_User_Payment.csv\n",
    "1.  Restaurant_User_Profile.csv: https://raw.githubusercontent.com/Jonas-Metz-verovis/verovis_Coding_Challenge/main/Data/Restaurant_User_Profile.csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "df_restaurant_accepts = pd.read_csv(\"https://raw.githubusercontent.com/Jonas-Metz-verovis/verovis_Coding_Challenge/main/Data/Restaurant_Accepts.csv\")"
   ]
  },
  {
   "source": [
    "# Exploratory Data Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Task: Inspect the loaded DataFrames and create a List of possible Input Features as well as possible Target Variables.\n",
    "\n",
    "#### Discuss/answer the following Questions:\n",
    "-   What are the Names of the Columns?\n",
    "-   What are the Data Types of the Columns?\n",
    "-   Do the Rows/Columns contain any Missing Values?\n",
    "-   Is this a supervised or unsupervised Machine Learning Problem?\n",
    "-   More specific: Is this a Classification, Regression or Clustering Problem?\n",
    "-   Which Machine Learning Algorithms could be used to solve this Challenge?\n",
    "\n",
    "INFO: Plots can often be very informative and provide valuable Insights! You can create Plots with e.g. [Matplotlib](https://matplotlib.org/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py) or [Seaborn](https://seaborn.pydata.org/tutorial/categorical.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "df_restaurant_accepts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "df_restaurant_accepts.Rpayment.value_counts()"
   ]
  },
  {
   "source": [
    "# Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Task: Preprocess the raw DataFrames (Cleaning, Formatting, ...) to be able to merge them into one clean DataFrame (Features + Targets) afterwards."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "df_restaurant_accepts = df_restaurant_accepts [df_restaurant_accepts.Rpayment != \"Carte_Blanche\"]\n",
    "df_restaurant_accepts.Rpayment.value_counts()"
   ]
  },
  {
   "source": [
    "### Task: Merge the preprocessed DataFrames into one DataFrame which contains a row-wise Combination of Input Features and the corresponding Target Variables.\n",
    "\n",
    "#### Discuss/answer the following Questions:\n",
    "-   What are the Names of the Key Columns which will be used to merge the DataFrames?\n",
    "-   What Type of Merge do you perform? What are the Requirements to successfully merge two DataFrames?\n",
    "\n",
    "INFO: If you don't know how to merge two DataFrames, you can check the [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Feature Engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Task (Optional): Use some of the Input Features to create new Features through Combination (drop the original Features afterwards)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Task: Inspect the Input Features. Which Levels of Measurement do they have? Which Encoding Methods are appropriate for each Level/Feature? Encode all Input Features appropriately. How about the Target Variables, do they need to be encoded as well?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Task: Summarize your Data Preprocessing Process and explain your Feature Selection/Engineering Choices.\n",
    "\n",
    "#### Discuss/answer the following Questions:\n",
    "-   Which Features did you select?\n",
    "-   How did you handle Missing Values?\n",
    "-   Which Difficulties did face while merging the DataFrames and how did you solve them?\n",
    "-   How did you encode the selected Categorical Variables and why are your Encoding Methods an appropriate Choice for these Features?\n",
    "-   Which Assumptions did you make?\n",
    "-   Which Hypotheses did you formulate about the Relationship between the selected Features and the Target Variables?\n",
    "-   What possible Limitations do you expect and what are the Reasons for your Expectation?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Add your Summary here ..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Task: Split your preprocessed and encoded DataFrame into Training and Test Input/Output Data (~25 % Test Data, random Split).\n",
    "\n",
    "#### Discuss: Based on your Preprocessing, could there be a Problem with some Form of [Target Leakage](https://www.kaggle.com/alexisbcook/data-leakage)? If yes, you either need to adjust your Preprocessing or perform the Train-Test-Split before the Data Preprocessing (and apply the same Preprocessing on the Test Dataset which you've applied to the Training Dataset)!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint\n",
    "X_train, X_test, y_train, y_test = train_test_split (preprocessed_data [input_features], preprocessed_data [target_variables], test_size = 0.25, shuffle = True)"
   ]
  },
  {
   "source": [
    "# Model Calculation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Task: Create a tree-based Model (Decision Tree/Random Forest) to predict the Rating of a Restaurant. Calculate the Accuracy Score of the Model (Training and Test Data). The Test Score will be used to grade this Challenge."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = model.score (X = X_test, y = y_test)"
   ]
  },
  {
   "source": [
    "## Solution: The Test Score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Test Score (Accuracy):\", test_score)"
   ]
  },
  {
   "source": [
    "### Task (Optional): Optimize your Feature Selection Workflow as well as the Hyperparameters of your tree-based Model. To do this properly, you need to split your Data into a Training/Validation/Test Dataset (e.g. 60/20/20 %). Train your Models using the Training Dataset. Select the best model based on its Score on the Validation Dataset. Only score the (final) best Model on the Test Dataset to create a true out-of-sample Test Score. You can, of course, use Scikit-Learn's Pipelines/Grid Search/Cross Validation/etc. Functionalities if you like. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Feel free to be creative ;-)\")"
   ]
  },
  {
   "source": [
    "# Result Postprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = y_test\n",
    "df_predictions [\"Predicted_Rating\"] = model.predict (X_test)\n",
    "df_predictions.head ()"
   ]
  },
  {
   "source": [
    "# Data Saving\n",
    "\n",
    "### Info (Google Colab)\n",
    "\n",
    "If you are working in Google Colab, you can save the Results to your Google Drive by running\n",
    "\n",
    "```\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "```\n",
    "\n",
    "You will be requested to authenticate with your Google Account.\n",
    "\n",
    "The Path to your Google Colab Notebooks Folder will be \"/content/drive/My Drive/Colab Notebooks\".\n",
    "\n",
    "The Commands can then use this Path:\n",
    "\n",
    "```\n",
    "os.makedirs (\"/content/drive/My Drive/Colab Notebooks/Results\", exist_ok=True)\n",
    "df_predictions.to_csv (\"/content/drive/My Drive/Colab Notebooks/Results/Restaurant_Rating_Predictions.csv\", index=False)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Task: Save a DataFrame which contains the actual Test Ratings as well as the corresponding Test Predictions to a CSV-File."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs (\"Results\", exist_ok=True)\n",
    "\n",
    "# INFO: This writes the CSV-File in a way which can be read by a German Microsoft Excel without any necessary Modifications\n",
    "df_predictions.to_csv (os.path.join (\"Results\", \"Restaurant_Rating_Predictions.csv\"), sep=\";\", decimal=\",\", header=True, index=False, encoding=\"utf-8\", float_format=\"%.4f\")\n",
    "print (\"The Predictions have been successfully saved to a CSV-File.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO: This writes the Model to joblib Pickle Dump File, which can be loaded during Inference. Please submit this File together with your Solution Notebook!\n",
    "dump(model, os.path.join(\"Results\", datetime.now().strftime(\"%Y%m%d_%H%M%S\") +'_Coding_Challenge_' + TEAM_NAME + '_CLF.joblib'))\n",
    "print (\"The fitted Model has been successfully saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}